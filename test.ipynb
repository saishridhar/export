{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('export')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVOUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['fid','gpt35','chatgpt','gpt4','newbing']\n",
    "dfs = []\n",
    "for m in models:\n",
    "    dfs.append(pd.read_csv(f'EVOUNA/{m}.csv'))\n",
    "    dfs[-1].dropna(inplace=True)\n",
    "    dfs[-1]['judge'].astype('int')\n",
    "    dfs[-1].drop('Unnamed: 0',axis=1,inplace=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sai/miniconda3/envs/cs594/lib/python3.13/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "\n",
    "lm = load('logr500mv3.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import evaluator\n",
    "\n",
    "r = []\n",
    "for i in range(len(dfs)):\n",
    "    pred = evaluator(dfs[i][['question','golden_answer','answer']],lm)\n",
    "    r.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>golden_answer</th>\n",
       "      <th>answer</th>\n",
       "      <th>judge</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>who got the first nobel prize in physics</td>\n",
       "      <td>Wilhelm Conrad Röntgen</td>\n",
       "      <td>Wilhelm Röntgen</td>\n",
       "      <td>True</td>\n",
       "      <td>fid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>which mode is used for short wave broadcast se...</td>\n",
       "      <td>Olivia</td>\n",
       "      <td>AM</td>\n",
       "      <td>False</td>\n",
       "      <td>fid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what does hp mean in war and order</td>\n",
       "      <td>hit points or health points</td>\n",
       "      <td>Health Points</td>\n",
       "      <td>True</td>\n",
       "      <td>fid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who wrote the first declaration of human rights</td>\n",
       "      <td>Cyrus</td>\n",
       "      <td>John Humphrey</td>\n",
       "      <td>False</td>\n",
       "      <td>fid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who is the owner of reading football club</td>\n",
       "      <td>Xiu Li Dai</td>\n",
       "      <td>Renhe Sports Management Ltd</td>\n",
       "      <td>False</td>\n",
       "      <td>fid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0           who got the first nobel prize in physics   \n",
       "1  which mode is used for short wave broadcast se...   \n",
       "2                 what does hp mean in war and order   \n",
       "3    who wrote the first declaration of human rights   \n",
       "4          who is the owner of reading football club   \n",
       "\n",
       "                 golden_answer                       answer  judge model  \n",
       "0       Wilhelm Conrad Röntgen              Wilhelm Röntgen   True   fid  \n",
       "1                       Olivia                           AM  False   fid  \n",
       "2  hit points or health points                Health Points   True   fid  \n",
       "3                        Cyrus                John Humphrey  False   fid  \n",
       "4                   Xiu Li Dai  Renhe Sports Management Ltd  False   fid  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef,confusion_matrix\n",
    "corrs = []\n",
    "for i in range(len(dfs)):\n",
    "    cor = matthews_corrcoef(r[i],dfs[i]['judge'].astype('int'))\n",
    "    corrs.append(cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8192311366274059,\n",
       " 0.6710243582779716,\n",
       " 0.6052006275053852,\n",
       " 0.5590805437431997,\n",
       " 0.5692999407562559]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1021,   21],\n",
       "       [ 543, 1435]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(dfs[1]['judge'].astype('int'),r[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bertscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "r = []\n",
    "for i in range(len(dfs)):\n",
    "    P,R,F = score(list(dfs[i][f'answer'].astype(str)),list(dfs[i]['golden_answer'].astype(str)),lang='en', rescale_with_baseline=True)\n",
    "    F = (F - min(F))/ (max(F)-min(F))\n",
    "    r.append(np.where(F > 0.5 ,1 ,0))\n",
    "\n",
    "r = np.array(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef,confusion_matrix\n",
    "corrs = []\n",
    "for i in range(len(dfs)):\n",
    "    cor = matthews_corrcoef(np.where(np.array(r[i]) > 0.5 ,1,0),np.where(dfs[i]['judge'] == True, 1,0))\n",
    "    corrs.append(cor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.027114861277846698,\n",
       " 0.262341318229872,\n",
       " 0.22780347260106842,\n",
       " 0.3131563256472302,\n",
       " 0.13290023540831086]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import initialize_model\n",
    "\n",
    "model,tokenizer = initialize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import get_semantic_similarity\n",
    "\n",
    "\n",
    "r = []\n",
    "for i in range(len(dfs)):\n",
    "    pred = dfs[i].apply(lambda row: get_semantic_similarity(row['question'],row['golden_answer'],row['answer'],model,tokenizer),axis=1)\n",
    "    r.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8157245935322697,\n",
       " 0.6618356962910176,\n",
       " 0.5916800893580882,\n",
       " 0.5424632444492016,\n",
       " 0.5580415277939176]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef,confusion_matrix\n",
    "corrs = []\n",
    "for i in range(len(dfs)):\n",
    "    cor = matthews_corrcoef(np.where(r[i] > 0.5,1,0),dfs[i]['judge'].astype('int'))\n",
    "    corrs.append(cor)\n",
    "corrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tf-text (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tf-text\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tf-text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLEURT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIVER-QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Validation set\n",
    "df = pd.read_csv('combinedv3.csv')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# Load Human_eval set\n",
    "df1 = pd.read_csv('cleaned_dataset.csv')\n",
    "df1.drop(df1.columns[0],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>dataset</th>\n",
       "      <th>prediction</th>\n",
       "      <th>eval</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where is the Hoppings funfair held?</td>\n",
       "      <td>Town Moor</td>\n",
       "      <td>aqa</td>\n",
       "      <td>According to the passage, the Hoppings funfair...</td>\n",
       "      <td>1</td>\n",
       "      <td>claude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who shares a name with an older type of transp...</td>\n",
       "      <td>Stagecoach North East</td>\n",
       "      <td>aqa</td>\n",
       "      <td>Based on the information provided, the company...</td>\n",
       "      <td>1</td>\n",
       "      <td>claude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What would be done for people who need more in...</td>\n",
       "      <td>link the local networks to national networks</td>\n",
       "      <td>aqa</td>\n",
       "      <td>Based on the given context, there isn't specif...</td>\n",
       "      <td>0</td>\n",
       "      <td>claude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What was affected by the refurbishment?</td>\n",
       "      <td>cinema</td>\n",
       "      <td>aqa</td>\n",
       "      <td>Based on the given context, the Pilgrim Street...</td>\n",
       "      <td>1</td>\n",
       "      <td>claude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Of the successful state schools listed, this s...</td>\n",
       "      <td>Heaton Manor School</td>\n",
       "      <td>aqa</td>\n",
       "      <td>To answer this question, I'll list the success...</td>\n",
       "      <td>1</td>\n",
       "      <td>claude</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0                Where is the Hoppings funfair held?   \n",
       "1  Who shares a name with an older type of transp...   \n",
       "2  What would be done for people who need more in...   \n",
       "3            What was affected by the refurbishment?   \n",
       "4  Of the successful state schools listed, this s...   \n",
       "\n",
       "                                        answers dataset  \\\n",
       "0                                     Town Moor     aqa   \n",
       "1                         Stagecoach North East     aqa   \n",
       "2  link the local networks to national networks     aqa   \n",
       "3                                        cinema     aqa   \n",
       "4                           Heaton Manor School     aqa   \n",
       "\n",
       "                                          prediction  eval   model  \n",
       "0  According to the passage, the Hoppings funfair...     1  claude  \n",
       "1  Based on the information provided, the company...     1  claude  \n",
       "2  Based on the given context, there isn't specif...     0  claude  \n",
       "3  Based on the given context, the Pilgrim Street...     1  claude  \n",
       "4  To answer this question, I'll list the success...     1  claude  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = ['claude_eval','mixtral_eval','ll70b_eval','ll8b_eval','phi_eval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claude_eval</th>\n",
       "      <th>mixtral_eval</th>\n",
       "      <th>ll70b_eval</th>\n",
       "      <th>ll8b_eval</th>\n",
       "      <th>phi_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   claude_eval  mixtral_eval  ll70b_eval  ll8b_eval  phi_eval\n",
       "0            1             1           1          1         1\n",
       "1            1             1           1          0         1\n",
       "2            0             0           0          0         0\n",
       "3            1             1           1          1         1\n",
       "4            1             0           1          0         0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df,df1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['answers', 'claude', 'mixtral', 'll70b', 'll8b', 'phi', 'questions',\n",
       "       'claude_eval', 'mixtral_eval', 'll70b_eval', 'll8b_eval', 'phi_eval'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of model names\n",
    "models = ['claude', 'mixtral', 'll70b', 'll8b', 'phi']\n",
    "\n",
    "# List of subdataset names\n",
    "subdatasets = ['aqa', 'squad', 'medqa', 'hotpotqa', 'triviaqa']\n",
    "\n",
    "# Melt the dataframe to transform model columns into rows\n",
    "melted_df = pd.melt(df, \n",
    "                    id_vars=['questions', 'answers'], \n",
    "                    value_vars=models,\n",
    "                    var_name='model', \n",
    "                    value_name='predictions')\n",
    "\n",
    "# Create a dataset column\n",
    "melted_df['dataset'] = np.repeat(subdatasets, 120 * len(models))\n",
    "\n",
    "# Sort the dataframe to ensure correct order\n",
    "melted_df = melted_df.sort_values(['dataset', 'questions', 'model']).reset_index(drop=True)\n",
    "\n",
    "# Reorder columns\n",
    "final_df = melted_df[['questions', 'answers', 'predictions', 'model', 'dataset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# List of model names\n",
    "models = ['claude', 'mixtral', 'll70b', 'll8b', 'phi']\n",
    "\n",
    "# List of subdataset names\n",
    "subdatasets = ['aqa', 'squad', 'medqa', 'hotpotqa', 'triviaqa']\n",
    "\n",
    "# Melt the dataframe for predictions\n",
    "melted_predictions = pd.melt(df2, \n",
    "                             id_vars=['questions', 'answers'], \n",
    "                             value_vars=models,\n",
    "                             var_name='model', \n",
    "                             value_name='predictions')\n",
    "\n",
    "# Melt the dataframe for evaluations\n",
    "melted_evaluations = pd.melt(df2, \n",
    "                             id_vars=['questions', 'answers'], \n",
    "                             value_vars=[f'{model}_eval' for model in models],\n",
    "                             var_name='model', \n",
    "                             value_name='evaluation')\n",
    "\n",
    "# Remove '_eval' suffix from the model column in melted_evaluations\n",
    "melted_evaluations['model'] = melted_evaluations['model'].str.replace('_eval', '')\n",
    "\n",
    "# Merge the melted predictions and evaluations\n",
    "melted_df = pd.merge(melted_predictions, melted_evaluations, \n",
    "                     on=['questions', 'answers', 'model'])\n",
    "\n",
    "# Create a dataset column\n",
    "melted_df['dataset'] = np.repeat(subdatasets, 120 * len(models))\n",
    "\n",
    "# Sort the dataframe to ensure correct order\n",
    "melted_df = melted_df.sort_values(['dataset', 'questions', 'model']).reset_index(drop=True)\n",
    "\n",
    "# Reorder columns\n",
    "final_df = melted_df[['questions', 'answers', 'predictions', 'evaluation', 'model', 'dataset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "questions      \"An Account of Further Discoveries in Air\" was...\n",
       "answers                                         Joseph Priestley\n",
       "predictions    According to the context, \"An Account of Furth...\n",
       "model                                                       ll8b\n",
       "dataset                                                 hotpotqa\n",
       "Name: 600, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.iloc[600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "lm = load('models/logr500mv3.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import evaluator\n",
    "\n",
    "r = []\n",
    "for d in subdatasets:\n",
    "    sub = final_df[final_df['dataset'] == d]\n",
    "    pred = evaluator(sub[['questions','answers','predictions']],lm)\n",
    "    r.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.array(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = pd.read_csv('eval_data/gpt_evaluated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt.drop('Unnamed: 0',inplace=True,axis=1)\n",
    "gpt.columns = df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the dataframe to transform model columns into rows\n",
    "melted_eval_df = pd.melt(gpt, \n",
    "                         value_vars=models,\n",
    "                         var_name='model', \n",
    "                         value_name='eval')\n",
    "\n",
    "# Create a dataset column\n",
    "melted_eval_df['dataset'] = np.repeat(subdatasets, 120 * len(models))\n",
    "\n",
    "# Sort the dataframe to ensure correct order\n",
    "melted_eval_df = melted_eval_df.sort_values(['dataset', 'model']).reset_index(drop=True)\n",
    "\n",
    "# Reorder columns\n",
    "gpt4_df = melted_eval_df[['eval', 'model', 'dataset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval</th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>claude</td>\n",
       "      <td>aqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>claude</td>\n",
       "      <td>aqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>claude</td>\n",
       "      <td>aqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>claude</td>\n",
       "      <td>aqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>claude</td>\n",
       "      <td>aqa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eval   model dataset\n",
       "0     1  claude     aqa\n",
       "1     1  claude     aqa\n",
       "2     0  claude     aqa\n",
       "3     1  claude     aqa\n",
       "4     1  claude     aqa"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "d_eval= []\n",
    "for i in range(len(subdatasets)):\n",
    "    d_eval.append(matthews_corrcoef(r[i],final_df[final_df['dataset']==subdatasets[i]]['evaluation']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>predictions</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"An Account of Further Discoveries in Air\" was...</td>\n",
       "      <td>Joseph Priestley</td>\n",
       "      <td>According to the information provided, \"An Acc...</td>\n",
       "      <td>1</td>\n",
       "      <td>claude</td>\n",
       "      <td>aqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The names of how many states of the USA start...</td>\n",
       "      <td>3</td>\n",
       "      <td>To answer this question, let's go through the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>claude</td>\n",
       "      <td>aqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"What was special about \"\"The Daily Courant\"\" ...</td>\n",
       "      <td>First daily newspaper</td>\n",
       "      <td>\"The Daily Courant\" was significant in the ear...</td>\n",
       "      <td>1</td>\n",
       "      <td>claude</td>\n",
       "      <td>aqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Which bass guitarist, songwriter, singer, and...</td>\n",
       "      <td>John Entwistle's</td>\n",
       "      <td>The bass guitarist, songwriter, singer, and ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>claude</td>\n",
       "      <td>aqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Which country launched the space station \"\"Sk...</td>\n",
       "      <td>The United States of America</td>\n",
       "      <td>The United States launched the space station \"...</td>\n",
       "      <td>1</td>\n",
       "      <td>claude</td>\n",
       "      <td>aqa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0  \"An Account of Further Discoveries in Air\" was...   \n",
       "1  \"The names of how many states of the USA start...   \n",
       "2  \"What was special about \"\"The Daily Courant\"\" ...   \n",
       "3  \"Which bass guitarist, songwriter, singer, and...   \n",
       "4  \"Which country launched the space station \"\"Sk...   \n",
       "\n",
       "                        answers  \\\n",
       "0              Joseph Priestley   \n",
       "1                             3   \n",
       "2         First daily newspaper   \n",
       "3              John Entwistle's   \n",
       "4  The United States of America   \n",
       "\n",
       "                                         predictions  evaluation   model  \\\n",
       "0  According to the information provided, \"An Acc...           1  claude   \n",
       "1  To answer this question, let's go through the ...           0  claude   \n",
       "2  \"The Daily Courant\" was significant in the ear...           1  claude   \n",
       "3  The bass guitarist, songwriter, singer, and ho...           1  claude   \n",
       "4  The United States launched the space station \"...           1  claude   \n",
       "\n",
       "  dataset  \n",
       "0     aqa  \n",
       "1     aqa  \n",
       "2     aqa  \n",
       "3     aqa  \n",
       "4     aqa  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.012289200239332837,\n",
       " 0.07033404116150534,\n",
       " 0.03978473466339667,\n",
       " 0.04512654702114134,\n",
       " 0.022023037791621264]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "d_eval= []\n",
    "for i in range(len(subdatasets)):\n",
    "    d_eval.append(matthews_corrcoef(gpt4_df[gpt4_df['dataset']==subdatasets[i]]['eval'],final_eval_df[final_eval_df['dataset']==subdatasets[i]]['eval']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('eval_data/combinedv3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6695088952305026,\n",
       " 0.6757920712461999,\n",
       " 0.6654317717087476,\n",
       " 0.6861900242568284,\n",
       " 0.6837815239372683]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.719231779434366,\n",
       " 0.6606556204940824,\n",
       " 0.6553162779841664,\n",
       " 0.70239465192972,\n",
       " 0.6327552621360103]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIVERQA-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Validation set\n",
    "df = pd.read_csv('combinedv3.csv')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# Load Human_eval set\n",
    "df1 = pd.read_csv('cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>dataset</th>\n",
       "      <th>prediction</th>\n",
       "      <th>eval</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where is the Hoppings funfair held?</td>\n",
       "      <td>Town Moor</td>\n",
       "      <td>aqa</td>\n",
       "      <td>According to the passage, the Hoppings funfair...</td>\n",
       "      <td>1</td>\n",
       "      <td>claude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who shares a name with an older type of transp...</td>\n",
       "      <td>Stagecoach North East</td>\n",
       "      <td>aqa</td>\n",
       "      <td>Based on the information provided, the company...</td>\n",
       "      <td>1</td>\n",
       "      <td>claude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What would be done for people who need more in...</td>\n",
       "      <td>link the local networks to national networks</td>\n",
       "      <td>aqa</td>\n",
       "      <td>Based on the given context, there isn't specif...</td>\n",
       "      <td>0</td>\n",
       "      <td>claude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What was affected by the refurbishment?</td>\n",
       "      <td>cinema</td>\n",
       "      <td>aqa</td>\n",
       "      <td>Based on the given context, the Pilgrim Street...</td>\n",
       "      <td>1</td>\n",
       "      <td>claude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Of the successful state schools listed, this s...</td>\n",
       "      <td>Heaton Manor School</td>\n",
       "      <td>aqa</td>\n",
       "      <td>To answer this question, I'll list the success...</td>\n",
       "      <td>1</td>\n",
       "      <td>claude</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0                Where is the Hoppings funfair held?   \n",
       "1  Who shares a name with an older type of transp...   \n",
       "2  What would be done for people who need more in...   \n",
       "3            What was affected by the refurbishment?   \n",
       "4  Of the successful state schools listed, this s...   \n",
       "\n",
       "                                        answers dataset  \\\n",
       "0                                     Town Moor     aqa   \n",
       "1                         Stagecoach North East     aqa   \n",
       "2  link the local networks to national networks     aqa   \n",
       "3                                        cinema     aqa   \n",
       "4                           Heaton Manor School     aqa   \n",
       "\n",
       "                                          prediction  eval   model  \n",
       "0  According to the passage, the Hoppings funfair...     1  claude  \n",
       "1  Based on the information provided, the company...     1  claude  \n",
       "2  Based on the given context, there isn't specif...     0  claude  \n",
       "3  Based on the given context, the Pilgrim Street...     1  claude  \n",
       "4  To answer this question, I'll list the success...     1  claude  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('eval',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = df1['claude-3.5-sonnet']\n",
    "l = pd.DataFrame(l)\n",
    "l.columns = ['eval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the series\n",
    "l = df1['claude-3.5-sonnet']\n",
    "l = pd.DataFrame(l)\n",
    "l.columns = ['eval']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df1['phi-3-mini']\n",
    "x = pd.DataFrame(x)\n",
    "x.columns = ['eval']  # Keep the same column name\n",
    "\n",
    "# Concatenate vertically (axis=0 is default)\n",
    "l = pd.concat([l, x], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>dataset</th>\n",
       "      <th>prediction</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where is the Hoppings funfair held?</td>\n",
       "      <td>Town Moor</td>\n",
       "      <td>aqa</td>\n",
       "      <td>According to the passage, the Hoppings funfair...</td>\n",
       "      <td>claude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who shares a name with an older type of transp...</td>\n",
       "      <td>Stagecoach North East</td>\n",
       "      <td>aqa</td>\n",
       "      <td>Based on the information provided, the company...</td>\n",
       "      <td>claude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What would be done for people who need more in...</td>\n",
       "      <td>link the local networks to national networks</td>\n",
       "      <td>aqa</td>\n",
       "      <td>Based on the given context, there isn't specif...</td>\n",
       "      <td>claude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What was affected by the refurbishment?</td>\n",
       "      <td>cinema</td>\n",
       "      <td>aqa</td>\n",
       "      <td>Based on the given context, the Pilgrim Street...</td>\n",
       "      <td>claude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Of the successful state schools listed, this s...</td>\n",
       "      <td>Heaton Manor School</td>\n",
       "      <td>aqa</td>\n",
       "      <td>To answer this question, I'll list the success...</td>\n",
       "      <td>claude</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0                Where is the Hoppings funfair held?   \n",
       "1  Who shares a name with an older type of transp...   \n",
       "2  What would be done for people who need more in...   \n",
       "3            What was affected by the refurbishment?   \n",
       "4  Of the successful state schools listed, this s...   \n",
       "\n",
       "                                        answers dataset  \\\n",
       "0                                     Town Moor     aqa   \n",
       "1                         Stagecoach North East     aqa   \n",
       "2  link the local networks to national networks     aqa   \n",
       "3                                        cinema     aqa   \n",
       "4                           Heaton Manor School     aqa   \n",
       "\n",
       "                                          prediction   model  \n",
       "0  According to the passage, the Hoppings funfair...  claude  \n",
       "1  Based on the information provided, the company...  claude  \n",
       "2  Based on the given context, there isn't specif...  claude  \n",
       "3  Based on the given context, the Pilgrim Street...  claude  \n",
       "4  To answer this question, I'll list the success...  claude  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['eval'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>dataset</th>\n",
       "      <th>prediction</th>\n",
       "      <th>model</th>\n",
       "      <th>eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where is the Hoppings funfair held?</td>\n",
       "      <td>Town Moor</td>\n",
       "      <td>aqa</td>\n",
       "      <td>According to the passage, the Hoppings funfair...</td>\n",
       "      <td>claude</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who shares a name with an older type of transp...</td>\n",
       "      <td>Stagecoach North East</td>\n",
       "      <td>aqa</td>\n",
       "      <td>Based on the information provided, the company...</td>\n",
       "      <td>claude</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What would be done for people who need more in...</td>\n",
       "      <td>link the local networks to national networks</td>\n",
       "      <td>aqa</td>\n",
       "      <td>Based on the given context, there isn't specif...</td>\n",
       "      <td>claude</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What was affected by the refurbishment?</td>\n",
       "      <td>cinema</td>\n",
       "      <td>aqa</td>\n",
       "      <td>Based on the given context, the Pilgrim Street...</td>\n",
       "      <td>claude</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Of the successful state schools listed, this s...</td>\n",
       "      <td>Heaton Manor School</td>\n",
       "      <td>aqa</td>\n",
       "      <td>To answer this question, I'll list the success...</td>\n",
       "      <td>claude</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0                Where is the Hoppings funfair held?   \n",
       "1  Who shares a name with an older type of transp...   \n",
       "2  What would be done for people who need more in...   \n",
       "3            What was affected by the refurbishment?   \n",
       "4  Of the successful state schools listed, this s...   \n",
       "\n",
       "                                        answers dataset  \\\n",
       "0                                     Town Moor     aqa   \n",
       "1                         Stagecoach North East     aqa   \n",
       "2  link the local networks to national networks     aqa   \n",
       "3                                        cinema     aqa   \n",
       "4                           Heaton Manor School     aqa   \n",
       "\n",
       "                                          prediction   model  eval  \n",
       "0  According to the passage, the Hoppings funfair...  claude     1  \n",
       "1  Based on the information provided, the company...  claude     1  \n",
       "2  Based on the given context, there isn't specif...  claude     0  \n",
       "3  Based on the given context, the Pilgrim Street...  claude     1  \n",
       "4  To answer this question, I'll list the success...  claude     1  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('combinedv4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aqa'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dataset'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUR MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input(question, answer, prediction):\n",
    "    premise = 'question: '+question+' '+'answer: '+answer\n",
    "    hypothesis = 'question: '+question+' '+'answer: '+prediction\n",
    "\n",
    "    return premise,hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model_name = \"MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "\n",
    "def get_semantic_similarity(question,answer,prediction):\n",
    "    premise,hypothesis = process_input(question,answer,prediction)\n",
    "    input = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "    output = model(input[\"input_ids\"].to(device))  # device = \"cuda:0\" or \"cpu\"\n",
    "    prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "    label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "    prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "    return prediction\n",
    "\n",
    "def get_lexical_similarity(answer, prediction):\n",
    "    answer_list = answer.split(\" \")\n",
    "    count = 0\n",
    "    for word in prediction.split(\" \"):\n",
    "        if word in answer_list:\n",
    "            count += 1\n",
    "    return count/len(answer_list)\n",
    "\n",
    "\n",
    "def evaluator(X,log_regr_model,device='cuda'):\n",
    "    lex_eval = X.apply(lambda x: get_lexical_similarity(x[X.columns[1]],x[X.columns[2]]), axis=1)\n",
    "    sem_eval = X.apply(lambda x: get_semantic_similarity(x[X.columns[0]],x[X.columns[1]],x[X.columns[2]],model,tokenizer), axis=1)\n",
    "    x = pd.DataFrame({'lex_eval':lex_eval,'sem_eval': sem_eval})\n",
    "    pred = log_regr_model.predict(x)\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs594",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
